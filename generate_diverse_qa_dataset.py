"""
ì „ë ¥ìˆ˜ìš” ë¬¸ì„œì—ì„œ GPT APIë¥¼ í™œìš©í•œ ë‹¤ì–‘í•œ í˜•íƒœì˜ í•™ìŠµ ë°ì´í„° ìƒì„±
- ì§§ì€ Q&A
- ê¸´ ë¶„ì„/ì„¤ëª…
- ìš”ì•½
- ë³´ê³ ì„œ ì‘ì„±
"""

import os
import glob
import json
from pathlib import Path
from openai import OpenAI
from tqdm import tqdm
import time
import traceback

# OpenAI API í‚¤ ì„¤ì •
api_key = os.getenv("OPENAI_API_KEY", "")
# íŠ¹ìˆ˜ ë¬¸ì ì œê±° (ëª¨ë“  ì¢…ë¥˜ì˜ ë”°ì˜´í‘œì™€ ì œì–´ ë¬¸ì)
if api_key:
    for quote_char in ['"', '"', '"', "'", '\u201c', '\u201d', '\u2018', '\u2019']:
        api_key = api_key.replace(quote_char, '')
    api_key = api_key.strip()
    api_key = api_key.encode('ascii', errors='ignore').decode('ascii')

client = OpenAI(api_key=api_key)

# ë‹¤ì–‘í•œ Task ìƒì„± í”„ë¡¬í”„íŠ¸
DIVERSE_TASK_PROMPT = """
ë‹¹ì‹ ì€ ì „ë ¥ìˆ˜ìš” ì˜ˆì¸¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ë¬¸ì„œì—ì„œ **5-8ê°œì˜ ë‹¤ì–‘í•œ í˜•íƒœì˜ í•™ìŠµ ë°ì´í„°**ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

## ë°ì´í„° ìœ í˜• (ë°˜ë“œì‹œ ë‹¤ì–‘í•˜ê²Œ ì„ì„ ê²ƒ):

### 1. ì§§ì€ Q&A (30% ë¹„ìœ¨)
- ê°„ë‹¨í•œ ì‚¬ì‹¤ í™•ì¸ ì§ˆë¬¸
- ë‹µë³€: 1-2ë¬¸ì¥

### 2. ë¶„ì„/ì„¤ëª… (30% ë¹„ìœ¨)
- ì¶”ì„¸ ë¶„ì„, ë¹„êµ, ì›ì¸ ì„¤ëª… ë“±
- ë‹µë³€: 3-5ë¬¸ì¥ì˜ êµ¬ì¡°í™”ëœ ì„¤ëª…

### 3. ìš”ì•½ (20% ë¹„ìœ¨)
- ë¬¸ì„œ ì „ì²´ ë˜ëŠ” ì¼ë¶€ ì„¹ì…˜ ìš”ì•½
- ë‹µë³€: 3-4ë¬¸ì¥ì˜ í•µì‹¬ ìš”ì•½

### 4. ë³´ê³ ì„œ ì‘ì„± (20% ë¹„ìœ¨)
- ì „ë¬¸ì ì¸ ë³´ê³ ì„œ í˜•íƒœ
- ë‹µë³€: êµ¬ì¡°í™”ëœ ê¸´ í˜•íƒœ (ì œëª©, ë³¸ë¬¸, ê²°ë¡ )

## ì¶œë ¥ í˜•ì‹:
```json
[
  {{
    "type": "short_qa",
    "question": "2019ë…„ 2ì›” ìµœëŒ€ë¶€í•˜ëŠ”?",
    "answer": "8,520ë§ŒkWì…ë‹ˆë‹¤."
  }},
  {{
    "type": "analysis",
    "question": "2018ë…„ê³¼ 2019ë…„ 2ì›” ì „ë ¥ìˆ˜ìš”ë¥¼ ë¹„êµ ë¶„ì„í•˜ì„¸ìš”.",
    "answer": "2018ë…„ 2ì›” ìµœëŒ€ë¶€í•˜ëŠ” 8,888ë§ŒkWì˜€ìœ¼ë‚˜, 2019ë…„ì€ 8,520ë§ŒkWë¡œ 4.1% ê°ì†Œí–ˆìŠµë‹ˆë‹¤. ì´ëŠ” ê¸°ì˜¨ ë³€í™”ì™€ ì—ë„ˆì§€ íš¨ìœ¨ ê°œì„ ì´ ì£¼ìš” ì›ì¸ìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤. í‰ê· ë¶€í•˜ ì—­ì‹œ 0.5% ê°ì†Œí•˜ì—¬ ì „ë°˜ì ì¸ ìˆ˜ìš” ê°ì†Œ ì¶”ì„¸ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤."
  }},
  {{
    "type": "summary",
    "question": "ì´ ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ ìš”ì•½í•˜ì„¸ìš”.",
    "answer": "2019ë…„ 2ì›” ì „ë ¥ìˆ˜ìš”ëŠ” ìµœëŒ€ë¶€í•˜ 8,520ë§ŒkW, í‰ê· ë¶€í•˜ 6,840ë§ŒkWë¡œ ì˜ˆì¸¡ë˜ì—ˆìŠµë‹ˆë‹¤. ì „ë…„ ëŒ€ë¹„ ê°ê° 4.1%, 0.5% ê°ì†Œí–ˆìœ¼ë©°, ê¸°ì˜¨ì€ í‰ë…„ê³¼ ë¹„ìŠ·í•˜ë‚˜ ë³€í™”í­ì´ í´ ê²ƒìœ¼ë¡œ ì „ë§ë˜ì—ˆìŠµë‹ˆë‹¤. ê°•ìˆ˜ëŸ‰ì€ ì „ë°˜ì— ë§ê³  í›„ë°˜ì—ëŠ” í‰ë…„ ìˆ˜ì¤€ì¼ ê²ƒìœ¼ë¡œ ì˜ˆìƒë˜ì—ˆìŠµë‹ˆë‹¤."
  }},
  {{
    "type": "report",
    "question": "2019ë…„ 2ì›” ì „ë ¥ìˆ˜ìš” ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.",
    "answer": "# 2019ë…„ 2ì›” ì „ë ¥ìˆ˜ìš” ë¶„ì„ ë³´ê³ ì„œ\\n\\n## 1. ê°œìš”\\n2019ë…„ 2ì›” ì „ë ¥ìˆ˜ìš”ëŠ” ìµœëŒ€ë¶€í•˜ 8,520ë§ŒkWë¡œ ì „ë…„ ëŒ€ë¹„ 4.1% ê°ì†Œê°€ ì˜ˆìƒë©ë‹ˆë‹¤.\\n\\n## 2. ì£¼ìš” ì§€í‘œ\\n- ìµœëŒ€ë¶€í•˜: 8,520ë§ŒkW (-4.1%)\\n- í‰ê· ë¶€í•˜: 6,840ë§ŒkW (-0.5%)\\n- ì˜ˆì¸¡ ì‹œì : 2019ë…„ 1ì›”\\n\\n## 3. ê¸°ìƒ ì¡°ê±´\\nê¸°ì˜¨ì€ í‰ë…„ê³¼ ë¹„ìŠ·í•˜ë‚˜ ë³€ë™ì„±ì´ í¬ë©°, ê°•ìˆ˜ëŸ‰ì€ ì „ë°˜ê¸°ì— ë§ì„ ê²ƒìœ¼ë¡œ ì „ë§ë©ë‹ˆë‹¤.\\n\\n## 4. ê²°ë¡ \\nì „ë…„ ëŒ€ë¹„ ê°ì†Œì„¸ê°€ ëšœë ·í•˜ë©°, ê¸°ì˜¨ ë³€í™”ì— ë”°ë¥¸ ë³€ë™ ê°€ëŠ¥ì„±ì„ ê³ ë ¤í•œ ìš´ì˜ì´ í•„ìš”í•©ë‹ˆë‹¤."
  }}
]
```

## ì¤‘ìš”:
- í•œê¸€ê³¼ ì˜ì–´ë¥¼ ì„ì–´ì„œ ìƒì„±í•˜ë˜, ê¸´ ë‹µë³€ì€ í•œê¸€ë¡œ
- typeì„ ëª…ì‹œì ìœ¼ë¡œ í‘œì‹œ
- ë‹µë³€ ê¸¸ì´ë¥¼ ë‹¤ì–‘í•˜ê²Œ (ì§§ì€ ê²ƒë¶€í„° ê¸´ ê²ƒê¹Œì§€)
- JSON í˜•íƒœë¡œë§Œ ì¶œë ¥ (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ë¶ˆí¬í•¨)

## ë¬¸ì„œ:
{document}
"""


def load_all_markdown_files(base_dir="."):
    """ëª¨ë“  ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë¡œë”©"""
    md_files = []

    for year in ["2019", "2020"]:
        pattern = f"{base_dir}/{year}_md/*.md"
        md_files.extend(glob.glob(pattern))

    for year in ["2021", "2022", "2023", "2024"]:
        pattern = f"{base_dir}/{year}_md/**/*.md"
        md_files.extend(glob.glob(pattern, recursive=True))

    print(f"ì´ {len(md_files)}ê°œì˜ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë°œê²¬")
    return md_files


def read_file_content(file_path):
    """íŒŒì¼ ë‚´ìš© ì½ê¸°"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            if len(content) > 10000:
                content = content[:10000] + "\n\n[ë¬¸ì„œê°€ ë„ˆë¬´ ê¸¸ì–´ ì¼ë¶€ë§Œ í¬í•¨ë¨]"
            return content
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
        return None


def generate_diverse_tasks(document_content, model="gpt-4o-mini", max_retries=5):
    """
    GPT APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œì—ì„œ ë‹¤ì–‘í•œ í˜•íƒœì˜ í•™ìŠµ ë°ì´í„° ìƒì„±
    Rate limit ë°©ì–´ ë¡œì§ í¬í•¨
    """
    prompt = DIVERSE_TASK_PROMPT.format(document=document_content)

    for attempt in range(max_retries):
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë ¥ìˆ˜ìš” ì˜ˆì¸¡ ë°ì´í„°ì—ì„œ ë‹¤ì–‘í•œ í˜•íƒœì˜ í•™ìŠµ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=3000,  # ê¸´ ë‹µë³€ì„ ìœ„í•´ ì¦ê°€
            )

            response_text = response.choices[0].message.content.strip()

            # JSON ì½”ë“œ ë¸”ë¡ ì œê±°
            if "```json" in response_text:
                response_text = response_text.split("```json")[1].split("```")[0].strip()
            elif "```" in response_text:
                response_text = response_text.split("```")[1].split("```")[0].strip()

            # JSON íŒŒì‹±
            tasks = json.loads(response_text)

            return tasks

        except json.JSONDecodeError as e:
            print(f"JSON íŒŒì‹± ì—ëŸ¬ (attempt {attempt + 1}/{max_retries}): {e}")
            print(f"ì‘ë‹µ ë‚´ìš©: {response_text[:200]}...")
            if attempt == max_retries - 1:
                return []
            time.sleep(2)

        except Exception as e:
            error_str = str(e)

            # Rate limit ì—ëŸ¬ ê°ì§€
            if "rate_limit" in error_str.lower() or "429" in error_str:
                wait_time = min(60, (2 ** attempt) * 5)  # Exponential backoff (ìµœëŒ€ 60ì´ˆ)
                print(f"âš ï¸  Rate limit ë„ë‹¬! {wait_time}ì´ˆ ëŒ€ê¸° ì¤‘... (attempt {attempt + 1}/{max_retries})")
                time.sleep(wait_time)
            else:
                print(f"API í˜¸ì¶œ ì—ëŸ¬ (attempt {attempt + 1}/{max_retries}): {e}")
                if attempt == 0:
                    print("Full traceback:")
                    traceback.print_exc()
                time.sleep(3)

            if attempt == max_retries - 1:
                return []

    return []


def process_all_documents(base_dir=".", output_file="diverse_qa_dataset.json", limit=None, delay=5.0):
    """
    ëª¨ë“  ë¬¸ì„œ ì²˜ë¦¬í•˜ì—¬ ë‹¤ì–‘í•œ í˜•íƒœì˜ í•™ìŠµ ë°ì´í„° ìƒì„±

    Args:
        base_dir: ë¬¸ì„œ ë””ë ‰í† ë¦¬
        output_file: ì¶œë ¥ íŒŒì¼ëª…
        limit: ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜ ì œí•œ
        delay: API í˜¸ì¶œ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ) - rate limit ë°©ì§€
    """
    md_files = load_all_markdown_files(base_dir)

    if limit:
        md_files = md_files[:limit]
        print(f"ì²˜ë¦¬ ì œí•œ: {limit}ê°œ íŒŒì¼ë§Œ ì²˜ë¦¬")

    # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ í™•ì¸ (ì´ì „ ì‹¤í–‰ ì¤‘ë‹¨ ì‹œ ì¬ê°œìš©)
    checkpoint_file = Path(base_dir) / f"{output_file}.checkpoint"
    processed_files = set()
    all_tasks = []

    if checkpoint_file.exists():
        print(f"âœ“ ì²´í¬í¬ì¸íŠ¸ ë°œê²¬: {checkpoint_file}")
        with open(checkpoint_file, 'r', encoding='utf-8') as f:
            checkpoint_data = json.load(f)
            all_tasks = checkpoint_data.get('tasks', [])
            processed_files = set(checkpoint_data.get('processed_files', []))
        print(f"  - ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼: {len(processed_files)}ê°œ")
        print(f"  - ì´ë¯¸ ìƒì„±ëœ Task: {len(all_tasks)}ê°œ")
        print(f"  - ë‚¨ì€ íŒŒì¼: {len([f for f in md_files if f not in processed_files])}ê°œ\n")

    failed_files = []

    print(f"\n{len(md_files)}ê°œ ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘...")
    print(f"â±ï¸  API í˜¸ì¶œ ê°„ê²©: {delay}ì´ˆ (rate limit ë°©ì§€)\n")

    for i, file_path in enumerate(tqdm(md_files, desc="ë‹¤ì–‘í•œ Task ìƒì„± ì¤‘")):
        # ì´ë¯¸ ì²˜ë¦¬í•œ íŒŒì¼ ìŠ¤í‚µ
        if file_path in processed_files:
            continue

        content = read_file_content(file_path)
        if not content or len(content.strip()) < 100:
            print(f"ìŠ¤í‚µ: {file_path} (ë‚´ìš© ë¶€ì¡±)")
            processed_files.add(file_path)
            continue

        tasks = generate_diverse_tasks(content)

        if tasks:
            for task in tasks:
                task['source_file'] = file_path
            all_tasks.extend(tasks)
            print(f"âœ“ {file_path}: {len(tasks)}ê°œ ìƒì„±")
        else:
            failed_files.append(file_path)
            print(f"âœ— {file_path}: ìƒì„± ì‹¤íŒ¨")

        processed_files.add(file_path)

        # 10ê°œ íŒŒì¼ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        if (i + 1) % 10 == 0:
            with open(checkpoint_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'tasks': all_tasks,
                    'processed_files': list(processed_files)
                }, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {len(all_tasks)}ê°œ Task")

        # Rate limit ë°©ì§€ë¥¼ ìœ„í•œ ëŒ€ê¸°
        if i < len(md_files) - 1:  # ë§ˆì§€ë§‰ íŒŒì¼ì´ ì•„ë‹ˆë©´
            time.sleep(delay)

    # ìµœì¢… ê²°ê³¼ ì €ì¥
    output_path = Path(base_dir) / output_file
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(all_tasks, f, ensure_ascii=False, indent=2)

    # ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì‚­ì œ (ì™„ë£Œ í›„)
    if checkpoint_file.exists():
        checkpoint_file.unlink()
        print(f"âœ“ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì‚­ì œ")

    # í†µê³„ ì¶œë ¥
    task_types = {}
    for task in all_tasks:
        task_type = task.get('type', 'unknown')
        task_types[task_type] = task_types.get(task_type, 0) + 1

    print(f"\n{'='*60}")
    print(f"âœ“ ì´ {len(all_tasks)}ê°œ í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ")
    print(f"âœ“ ì €ì¥ ìœ„ì¹˜: {output_path}")
    print(f"\nğŸ“Š Task ìœ í˜•ë³„ ë¶„í¬:")
    for task_type, count in task_types.items():
        print(f"  - {task_type}: {count}ê°œ")
    print(f"\nâœ— ì‹¤íŒ¨í•œ íŒŒì¼: {len(failed_files)}ê°œ")

    if failed_files:
        print(f"\nì‹¤íŒ¨í•œ íŒŒì¼ ëª©ë¡:")
        for f in failed_files[:10]:
            print(f"  - {f}")
        if len(failed_files) > 10:
            print(f"  ... ì™¸ {len(failed_files) - 10}ê°œ")

    return all_tasks


def convert_to_sft_format(dataset_file, output_file="diverse_sft_dataset.jsonl"):
    """
    ë‹¤ì–‘í•œ í˜•íƒœì˜ ë°ì´í„°ë¥¼ SFTìš© í¬ë§·ìœ¼ë¡œ ë³€í™˜
    """
    with open(dataset_file, 'r', encoding='utf-8') as f:
        tasks = json.load(f)

    sft_data = []
    for task in tasks:
        sft_data.append({
            "messages": [
                {"role": "user", "content": task['question']},
                {"role": "assistant", "content": task['answer']}
            ],
            "type": task.get('type', 'unknown')
        })

    # JSONL í˜•íƒœë¡œ ì €ì¥
    output_path = Path(dataset_file).parent / output_file
    with open(output_path, 'w', encoding='utf-8') as f:
        for item in sft_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    print(f"\nâœ“ SFT í¬ë§· ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {output_path}")
    print(f"âœ“ ì´ {len(sft_data)}ê°œ ëŒ€í™” ìŒ")

    return sft_data


if __name__ == "__main__":
    if not os.getenv("OPENAI_API_KEY"):
        print("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        exit(1)

    # 1. ë‹¤ì–‘í•œ í˜•íƒœì˜ í•™ìŠµ ë°ì´í„° ìƒì„±
    tasks = process_all_documents(
        base_dir=".",
        output_file="diverse_qa_dataset.json",
        limit=5,  # í…ŒìŠ¤íŠ¸: limit=5, ì „ì²´: limit=None
        delay=5.0  # API í˜¸ì¶œ ê°„ê²© (ì´ˆ) - rate limit ë°©ì§€
    )

    # 2. SFT í¬ë§·ìœ¼ë¡œ ë³€í™˜
    if tasks:
        convert_to_sft_format("diverse_qa_dataset.json", "diverse_sft_dataset.jsonl")

        # ìƒ˜í”Œ ì¶œë ¥ (ê° íƒ€ì…ë³„)
        print("\n=== ìƒ˜í”Œ ë°ì´í„° (íƒ€ì…ë³„) ===")
        task_types_shown = set()
        for i, task in enumerate(tasks):
            task_type = task.get('type', 'unknown')
            if task_type not in task_types_shown:
                print(f"\n[{task_type.upper()}]")
                print(f"ì§ˆë¬¸: {task['question']}")
                print(f"ë‹µë³€: {task['answer'][:200]}...")
                task_types_shown.add(task_type)
                if len(task_types_shown) >= 4:
                    break
